{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SahilKharya/Gen_AI_Projects/blob/main/Play_Store_Apps_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "idEvhOXix_jg",
        "run_control": {
          "frozen": true
        }
      },
      "source": [
        "## **Play Store Apps Analysis**\n",
        "Imagine you're diving into a big dataset from the Google Play Store. You'll be using Python to explore it and find interesting insights.\n",
        "\n",
        "First, the data will be cleaned up using Python to fix any mistakes and make it look neat.\n",
        "\n",
        "Once the data is clean, SQL will be used to find hidden patterns and correlations in the data. However, in this project, we are only going to work on cleaning tasks.\n",
        "\n",
        "Visualizations will also be created to make it easier to understand the data. Charts and graphs will show patterns and trends.\n",
        "\n",
        "By the end, you'll have learned a lot about how to make smart decisions using data. This project helps everyone understand how to use data to make better choices in our digital world.\n",
        "\n",
        "Join this adventure as you explore the Google Play Store dataset. Get ready to find out all sorts of interesting things about your favorite apps!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "JUtT3DDuzMg3",
        "run_control": {
          "frozen": true
        }
      },
      "source": [
        "### **Install the required libraries**\n",
        "**langchain**: An open source framework for building applications based on large language models (LLMs).\n",
        "\n",
        "**langchain_experimental**: An experimental extension of the langchain library, offering cutting-edge features and functionalities for advanced natural language processing tasks.\n",
        "\n",
        "**openai**: A powerful Python library developed by OpenAI, offering state-of-the-art natural language processing capabilities. It provides tools and utilities for a wide range of NLP tasks, including text generation, text classification, language translation, and more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IeK4Va9GzpWG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57f92b61-a81b-4fcd-9d92-9b13abeff678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.11-py3-none-any.whl (807 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.5/807.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.25 (from langchain)\n",
            "  Downloading langchain_community-0.0.27-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.29 (from langchain)\n",
            "  Downloading langchain_core-0.1.30-py3-none-any.whl (256 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.9/256.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.23-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.6/66.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.29->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.29->langchain) (23.2)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.29->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.29->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: orjson, mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.11 langchain-community-0.0.27 langchain-core-0.1.30 langchain-text-splitters-0.0.1 langsmith-0.1.23 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.9.15 typing-inspect-0.9.0\n",
            "Collecting langchain_experimental\n",
            "  Downloading langchain_experimental-0.0.53-py3-none-any.whl (173 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.7/173.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain<0.2.0,>=0.1.8 in /usr/local/lib/python3.10/dist-packages (from langchain_experimental) (0.1.11)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.27 in /usr/local/lib/python3.10/dist-packages (from langchain_experimental) (0.1.30)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.8->langchain_experimental) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.8->langchain_experimental) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.8->langchain_experimental) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.8->langchain_experimental) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.8->langchain_experimental) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.8->langchain_experimental) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.25 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.8->langchain_experimental) (0.0.27)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.8->langchain_experimental) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.8->langchain_experimental) (0.1.23)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.8->langchain_experimental) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.8->langchain_experimental) (2.6.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.8->langchain_experimental) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.8->langchain_experimental) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.27->langchain_experimental) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.27->langchain_experimental) (23.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.8->langchain_experimental) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.8->langchain_experimental) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.8->langchain_experimental) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.8->langchain_experimental) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.8->langchain_experimental) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.27->langchain_experimental) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.27->langchain_experimental) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.27->langchain_experimental) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.8->langchain_experimental) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.8->langchain_experimental) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.8->langchain_experimental) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.8->langchain_experimental) (3.9.15)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.8->langchain_experimental) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.8->langchain_experimental) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.8->langchain_experimental) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.8->langchain_experimental) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.8->langchain_experimental) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.8->langchain_experimental) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.8->langchain_experimental) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.8->langchain_experimental) (1.0.0)\n",
            "Installing collected packages: langchain_experimental\n",
            "Successfully installed langchain_experimental-0.0.53\n",
            "Collecting openai\n",
            "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install langchain_experimental\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "b5NxH3t70dtJ",
        "run_control": {
          "frozen": true
        }
      },
      "source": [
        "### Task 1: Data Preparation: Importing Libraries, Setting up API Key, and Reading Data\n",
        "Before we start our analysis, let's ensure we have everything we need. First, we'll import the required libraries. Then, we'll set up our GPT-3.5 API key for access. Finally, we'll read the data from our CSV file and get everything ready.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**To obtain an API key for OpenAI, follow these steps:**\n",
        "\n",
        "* Log in to your OpenAI account at OpenAI Login Page(https://platform.openai.com/login?launch).\n",
        "\n",
        "* Generate and retrieve your API key by visiting API Key Generation Page.(https://platform.openai.com/api-keys)\n",
        "\n",
        "\n",
        "\n",
        "Download the Playstore Datasets.(https://drive.google.com/drive/folders/1l_TabQZpTRypVKwVcHoD98YSAyXZOu91?usp=sharing)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "f67SEm4qzpYv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "#Setup the api key\n",
        "os.environ['OPENAI_API_KEY']=\"Your-api-key\"\n",
        "\n",
        "#Load the dataset (playstore_apps.csv) and assign it to a variable 'df'.\n",
        "df = pd.read_csv('playstore_apps.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "og3uUjNho8R7",
        "run_control": {
          "frozen": true
        }
      },
      "source": [
        "### Task 2: Display Top 5 Records.\n",
        "\n",
        "Great! Initializing our agent(OpenAI) is our next step. Once that's done, we'll create a prompt to display the first 5 records from our data table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "pRgsw4gjmu1F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b87b7933-160f-4973-f7ee-e0cdedb0dd63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to use the head() function to display the first 5 rows of the dataframe.\n",
            "Action: python_repl_ast\n",
            "Action Input: print(df.head())\u001b[0m\u001b[36;1m\u001b[1;3m                                                 App        Category  Rating  \\\n",
            "0     Photo Editor & Candy Camera & Grid & ScrapBook  ART_AND_DESIGN     4.1   \n",
            "1                                Coloring book moana  ART_AND_DESIGN     3.9   \n",
            "2  U Launcher Lite – FREE Live Cool Themes, Hide ...  ART_AND_DESIGN     4.7   \n",
            "3                              Sketch - Draw & Paint  ART_AND_DESIGN     4.5   \n",
            "4              Pixel Draw - Number Art Coloring Book  ART_AND_DESIGN     4.3   \n",
            "\n",
            "    Reviews    Installs  Type  Price Content Rating                     Genres  \n",
            "0     159.0     10000.0  Free    0.0       Everyone               Art & Design  \n",
            "1     967.0    500000.0  Free    0.0       Everyone  Art & Design;Pretend Play  \n",
            "2   87510.0   5000000.0  Free    0.0       Everyone               Art & Design  \n",
            "3  215644.0  50000000.0  Free    0.0           Teen               Art & Design  \n",
            "4     967.0    100000.0  Free    0.0       Everyone    Art & Design;Creativity  \n",
            "\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: The top 5 records from the dataframe are displayed above.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'display top 5 records from df',\n",
              " 'output': 'The top 5 records from the dataframe are displayed above.'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Initializing the agent\n",
        "agent = create_pandas_dataframe_agent(OpenAI(temperature=0),\n",
        "              df, verbose=True)\n",
        "\n",
        "# write your prompt using the agent\n",
        "agent('display top 5 records from df')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "_WA0pK5n53dw",
        "run_control": {
          "frozen": true
        }
      },
      "source": [
        "### Task 3: Determine the Shape(Count Rows and Columns) of the Dataset.\n",
        "Great! For our next step, let's create a prompt to gather information about the shape of our playstore app dataset. This will help us understand how many rows and columns it contains."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "mPkA7zd953k_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "794601fd-9269-4890-ab31-a123f74fb8d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to use the shape attribute of the dataframe to get the number of rows and columns\n",
            "Action: python_repl_ast\n",
            "Action Input: df.shape\u001b[0m\u001b[36;1m\u001b[1;3m(10355, 9)\u001b[0m\u001b[32;1m\u001b[1;3m10355 rows and 9 columns\n",
            "Final Answer: The shape of the dataset is (10355, 9).\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'what is the shape of the dataset',\n",
              " 'output': 'The shape of the dataset is (10355, 9).'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# write your prompt using the agent\n",
        "agent('what is the shape of the dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "6cbi52zG7E8U",
        "run_control": {
          "frozen": true
        }
      },
      "source": [
        "### Task 4: Finding the Missing data.\n",
        "Wow! We've successfully found out the shape of the dataset. Now, let's create a prompt to ask our agent to help us find details about any missing information in the data table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xaxUndfi7FFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f778219-b023-470e-88cf-d34bb408f05c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to use the isnull() function to check for missing values, and then use the sum() function to count them.\n",
            "Action: python_repl_ast\n",
            "Action Input: df.isnull().sum()\u001b[0m\u001b[36;1m\u001b[1;3mApp                  0\n",
            "Category             0\n",
            "Rating            1465\n",
            "Reviews              1\n",
            "Installs             1\n",
            "Type                 1\n",
            "Price                1\n",
            "Content Rating       1\n",
            "Genres               0\n",
            "dtype: int64\u001b[0m\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: There are 1465 missing values in the \"Rating\" column, and 1 missing value in the \"Reviews\", \"Installs\", \"Type\", \"Price\", and \"Content Rating\" columns. There are no missing values in the \"App\" and \"Genres\" columns.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'how many missing values are there in each column',\n",
              " 'output': 'There are 1465 missing values in the \"Rating\" column, and 1 missing value in the \"Reviews\", \"Installs\", \"Type\", \"Price\", and \"Content Rating\" columns. There are no missing values in the \"App\" and \"Genres\" columns.'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# write your prompt using the agent\n",
        "agent('how many missing values are there in each column')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "dd_5WaQH9C2u",
        "run_control": {
          "frozen": true
        }
      },
      "source": [
        "### Task 5: Identifying Duplicate Rows.\n",
        "Fantastic! We've successfully found the missing values. Now, let's create a prompt to ask our agent to count the number of duplicate rows in the playstore app dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "3V9zZ_np9C8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74c4e07c-f213-4567-c649-353d04df00bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to find a way to count the number of duplicate rows in each column\n",
            "Action: python_repl_ast\n",
            "Action Input: df.duplicated().sum()\u001b[0m\u001b[36;1m\u001b[1;3m0\u001b[0m\u001b[32;1m\u001b[1;3m0 means there are no duplicate rows in the dataframe\n",
            "Final Answer: There are no duplicate rows in each column.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'how many duplicate rows are there in each column',\n",
              " 'output': 'There are no duplicate rows in each column.'}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# write your prompt using the agent\n",
        "agent('how many duplicate rows are there in each column')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "xQolPJMY-xGr",
        "run_control": {
          "frozen": true
        }
      },
      "source": [
        "### Task 6: Dropping Unnecessary Columns.\n",
        "Fantastic! We successfully found the duplicates. Now, let's create a prompt to ask our agent to remove the Last Updated, Current Ver, Android Ver and Size columns from the playstore dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "x226UO76-xNx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3335c7ec-fd70-4660-e844-a43d8f847623"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to use the drop function to remove the specified columns\n",
            "Action: python_repl_ast\n",
            "Action Input: df.drop(columns=['Last Updated', 'Current Ver', 'Android Ver', 'Size'], inplace=True)\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m The specified columns have been removed and the dataframe has been updated\n",
            "Final Answer: The updated dataframe is now:\n",
            "|    | App                                                | Category       |   Rating |   Reviews |   Installs | Type   |   Price | Content Rating   | Genres                    |\n",
            "|---:|:---------------------------------------------------|:---------------|---------:|----------:|-----------:|:-------|--------:|:-----------------|:--------------------------|\n",
            "|  0 | Photo Editor & Candy Camera & Grid & ScrapBook     | ART_AND_DESIGN |      4.1 |       159 |  10000     | Free   |       0 | Everyone         | Art & Design              |\n",
            "|  1 | Coloring book moana                                | ART_AND_DESIGN |      3.9 |       967 | 500000     | Free   |       0 | Everyone         | Art & Design;Pretend Play |\n",
            "|  2 | U Launcher Lite – FREE Live Cool Themes, Hide Apps | ART_AND_DESIGN |      4.7 |     87510 |      5e+06 | Free   |       0 | Everyone         | Art & Design              |\n",
            "|  3 | Sketch - Draw &\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'remove the Last Updated, Current Ver, Android Ver and Size columns columns from the dataset and update the df',\n",
              " 'output': 'The updated dataframe is now:\\n|    | App                                                | Category       |   Rating |   Reviews |   Installs | Type   |   Price | Content Rating   | Genres                    |\\n|---:|:---------------------------------------------------|:---------------|---------:|----------:|-----------:|:-------|--------:|:-----------------|:--------------------------|\\n|  0 | Photo Editor & Candy Camera & Grid & ScrapBook     | ART_AND_DESIGN |      4.1 |       159 |  10000     | Free   |       0 | Everyone         | Art & Design              |\\n|  1 | Coloring book moana                                | ART_AND_DESIGN |      3.9 |       967 | 500000     | Free   |       0 | Everyone         | Art & Design;Pretend Play |\\n|  2 | U Launcher Lite – FREE Live Cool Themes, Hide Apps | ART_AND_DESIGN |      4.7 |     87510 |      5e+06 | Free   |       0 | Everyone         | Art & Design              |\\n|  3 | Sketch - Draw &'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# write your prompt using the agent\n",
        "agent('remove the Last Updated, Current Ver, Android Ver and Size columns columns from the dataset and update the df')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "AeX7d4aTCZo4",
        "run_control": {
          "frozen": true
        }
      },
      "source": [
        "### Task 7: Removing Duplicate Rows.\n",
        "Great progress! We were successful in dropped the columns. Now, let's create a prompt to ask our agent to remove duplicate rows from the playstore dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0TJ221DmCZ1W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4e6fde3-7287-4340-9854-9303567dc242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to use the drop_duplicates() function from pandas to remove duplicate rows.\n",
            "Action: python_repl_ast\n",
            "Action Input: df.drop_duplicates(keep='first', inplace=True)\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: df.drop_duplicates(keep='first', inplace=True)\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': '\\nPlease write code to remove duplicate rows while keeping the first occurrence of each duplicated row, and update the orginal df',\n",
              " 'output': \"df.drop_duplicates(keep='first', inplace=True)\"}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# write your prompt using the agent\n",
        "agent(\"\"\"\n",
        "Please write code to remove duplicate rows while keeping the first occurrence of each duplicated row, and update the orginal df\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "iPeHjk0m_tlX",
        "run_control": {
          "frozen": true
        }
      },
      "source": [
        "### Task 8: Filling missing values in the DataFrame.\n",
        "Good job! The duplicated rows have been successfully dropped. Let's now build a prompt to request that our agent to fill missing values in the Rating, Reviews, Price and Installs columns with the mean. Fill missing values in the Type column with the string 'Free'. Finally, fill missing values in the Content Rating column with the string 'Everyone'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "h-LKAq-O_tsI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f2b8a03-de6d-482b-a98f-29a98e6ecf0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to use the fillna() function to fill in the missing values in the specified columns.\n",
            "Action: python_repl_ast\n",
            "Action Input: df.fillna(df.mean(), inplace=True)\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<string>:1: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m I have filled in the missing values with the mean, but I still need to fill in the missing values in the Type and Content Rating columns.\n",
            "Action: python_repl_ast\n",
            "Action Input: df['Type'].fillna('Free', inplace=True)\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m I have now filled in the missing values in the Type column, but I still need to fill in the missing values in the Content Rating column.\n",
            "Action: python_repl_ast\n",
            "Action Input: df['Content Rating'].fillna('Everyone', inplace=True)\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m I have now filled in all the missing values in the dataframe.\n",
            "Final Answer: df\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"\\nPlease write code to \\n- fill missing values in the Rating, Reviews, Price and Installs columns with the mean\\n- Fill missing values in the Type column with the string 'Free'\\n- fill missing values in the Content Rating column with the string 'Everyone'\\n\\nand update the orginal df\",\n",
              " 'output': 'df'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# write your prompt using the agent\n",
        "agent(\"\"\"\n",
        "Please write code to\n",
        "- fill missing values in the Rating, Reviews, Price and Installs columns with the mean\n",
        "- Fill missing values in the Type column with the string 'Free'\n",
        "- fill missing values in the Content Rating column with the string 'Everyone'\n",
        "\n",
        "and update the orginal df\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "pBhlarQOBD8x",
        "run_control": {
          "frozen": true
        }
      },
      "source": [
        "### Task 9: Eliminating Data Anomalies.\n",
        "\n",
        "Wow! We've successfully filled the missing values. Now, let's develop a prompt to tell our agent to remove the rows with Category equal to '1.9' from the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "eXWTThgqBEEx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ae80872-5230-4359-c135-438d4a57d9db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to use the drop() function to remove rows from the dataframe.\n",
            "Action: python_repl_ast\n",
            "Action Input: df.drop(df[df['Category'] == '1.9'].index, inplace=True)\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m I need to specify the condition for the rows to be dropped, which is when the value in the 'Category' column is equal to '1.9'.\n",
            "Action: python_repl_ast\n",
            "Action Input: df[df['Category'] == '1.9'].index\u001b[0m\u001b[36;1m\u001b[1;3mInt64Index([], dtype='int64')\u001b[0m\u001b[32;1m\u001b[1;3m This shows that there are no rows with a value of '1.9' in the 'Category' column.\n",
            "Action: python_repl_ast\n",
            "Action Input: df.drop(df[df['Category'] == '1.9'].index, inplace=True)\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m Now I need to update the original dataframe by setting inplace=True.\n",
            "Action: python_repl_ast\n",
            "Action Input: df\u001b[0m\u001b[36;1m\u001b[1;3m                                                     App             Category  \\\n",
            "0         Photo Editor & Candy Camera & Grid & ScrapBook       ART_AND_DESIGN   \n",
            "1                                    Coloring book moana       ART_AND_DESIGN   \n",
            "2      U Launcher Lite – FREE Live Cool Themes, Hide ...       ART_AND_DESIGN   \n",
            "3                                  Sketch - Draw & Paint       ART_AND_DESIGN   \n",
            "4                  Pixel Draw - Number Art Coloring Book       ART_AND_DESIGN   \n",
            "...                                                  ...                  ...   \n",
            "10836                                   Sya9a Maroc - FR               FAMILY   \n",
            "10837                   Fr. Mike Schmitz Audio Teachings               FAMILY   \n",
            "10838                             Parkinson Exercices FR              MEDICAL   \n",
            "10839                      The SCP Foundation DB fr nn5n  BOOKS_AND_REFERENCE   \n",
            "10840      iHoroscope - 2018 Daily Horoscope & Astrology            LIFESTYLE   \n",
            "\n",
            "         Rating   Reviews    Installs  Type  Price Content Rating  \\\n",
            "0      4.100000     159.0     10000.0  Free    0.0       Everyone   \n",
            "1      3.900000     967.0    500000.0  Free    0.0       Everyone   \n",
            "2      4.700000   87510.0   5000000.0  Free    0.0       Everyone   \n",
            "3      4.500000  215644.0  50000000.0  Free    0.0           Teen   \n",
            "4      4.300000     967.0    100000.0  Free    0.0       Everyone   \n",
            "...         ...       ...         ...   ...    ...            ...   \n",
            "10836  4.500000      38.0      5000.0  Free    0.0       Everyone   \n",
            "10837  5.000000       4.0       100.0  Free    0.0       Everyone   \n",
            "10838  4.189551       3.0      1000.0  Free    0.0       Everyone   \n",
            "10839  4.500000     114.0      1000.0  Free    0.0     Mature 17+   \n",
            "10840  4.500000  398307.0  10000000.0  Free    0.0       Everyone   \n",
            "\n",
            "                          Genres  \n",
            "0                   Art & Design  \n",
            "1      Art & Design;Pretend Play  \n",
            "2                   Art & Design  \n",
            "3                   Art & Design  \n",
            "4        Art & Design;Creativity  \n",
            "...                          ...  \n",
            "10836                  Education  \n",
            "10837                  Education  \n",
            "10838                    Medical  \n",
            "10839          Books & Reference  \n",
            "10840                  Lifestyle  \n",
            "\n",
            "[10355 rows x 9 columns]\u001b[0m\u001b[32;1m\u001b[1;3m I can see that the rows with a value of '1.9' in the 'Category' column have been dropped.\n",
            "Final Answer: The updated dataframe with the rows dropped is shown above.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"\\nPlease write code to drop the rows where the values of 'Category' column equal to '1.9' from the DataFrame.\\nand update the orginal df\",\n",
              " 'output': 'The updated dataframe with the rows dropped is shown above.'}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# write your prompt using the agent\n",
        "agent(\"\"\"\n",
        "Please write code to drop the rows where the values of 'Category' column equal to '1.9' from the DataFrame.\n",
        "and update the orginal df\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "SSrn5uwWDcH-",
        "run_control": {
          "frozen": true
        }
      },
      "source": [
        "### Task 10: Check App Distribution.\n",
        "\n",
        "Fantastic! We've successfully removed the anamolies. Now, let's construct a prompt that tells our agent to count occurrences of each unique value in the Type column."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9BSXzZfbXD0q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "nyVdUdYzDcO6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff2aa185-9ad5-41dc-848e-cb66967a2229"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to use the value_counts() function to count the occurrences of each unique value in the Type column.\n",
            "Action: python_repl_ast\n",
            "Action Input: df['Type'].value_counts()\u001b[0m\u001b[36;1m\u001b[1;3mFree    9590\n",
            "Paid     765\n",
            "0          1\n",
            "Name: Type, dtype: int64\u001b[0m\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The final answer is that there are 9590 occurrences of \"Free\", 765 occurrences of \"Paid\", and 1 occurrence of \"0\" in the Type column.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': '\\nPlease write code to count occurrences of each unique value in the Type column',\n",
              " 'output': 'The final answer is that there are 9590 occurrences of \"Free\", 765 occurrences of \"Paid\", and 1 occurrence of \"0\" in the Type column.'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# write your prompt using the agent\n",
        "agent(\"\"\"\n",
        "Please write code to count occurrences of each unique value in the Type column\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "siiVL2_UXA7Z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "P3-O18xiECEC",
        "run_control": {
          "frozen": true
        }
      },
      "source": [
        "### Task 11:  Cleaning App Name.\n",
        "Amazing Let's now develop a prompt to advise our helper to update the 'df' DataFrame by identifying rows where App column starts with '?'. And remove those rows in the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Jsl9zz1cECLh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9e912ba-d24e-45f7-b500-498bee5f0abc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to use the pandas library to manipulate the dataframe\n",
            "Action: python_repl_ast\n",
            "Action Input: import pandas as pd\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mI need to use the .loc function to select rows based on a condition\n",
            "Action: python_repl_ast\n",
            "Action Input: df.loc[df['App'].str.startswith('?')]\u001b[0m\u001b[36;1m\u001b[1;3m                                                     App             Category  \\\n",
            "313                  ?? Comics - Manga,Novel and Stories               COMICS   \n",
            "321    ?Ranobbe complete free? Novelba - Free app tha...               COMICS   \n",
            "882    ?? Football Wallpapers 4K | Full HD Background...        ENTERTAINMENT   \n",
            "1081                                               ??Cep              FINANCE   \n",
            "1488   ???: Buying a house, selling a house, renting ...       HOUSE_AND_HOME   \n",
            "1592              ????? Astrology - Min Thein Kha BayDin            LIFESTYLE   \n",
            "2575      ?? WhatsLov: Smileys of love, stickers and GIF               SOCIAL   \n",
            "3750                                         ??? ???????   NEWS_AND_MAGAZINES   \n",
            "3824   ??NAVITIME?Timetable & Route Search in Japan T...  MAPS_AND_NAVIGATION   \n",
            "3960                       ? MultiCraft ? Free Miner! ??                 GAME   \n",
            "4193                                           ??? ??? H       ART_AND_DESIGN   \n",
            "4362                                         ?? I'm rich            LIFESTYLE   \n",
            "5513                                         ??? AQ?????               FAMILY   \n",
            "5569                            ?Miku AR Camera?Mikuture               FAMILY   \n",
            "5698                                              ??AV??  BOOKS_AND_REFERENCE   \n",
            "6006                        ????? ???? ???? BD Bangla TV               FAMILY   \n",
            "6334                             ??? - ????, ?????, BJ??        VIDEO_PLAYERS   \n",
            "6418                                       ?????BL??????               FAMILY   \n",
            "6420                                         ???? BL ???               COMICS   \n",
            "7183                              ?????? ??? CD 2019 PRO    AUTO_AND_VEHICLES   \n",
            "7187                     ???I Smart Remote MP3 CD Player                TOOLS   \n",
            "7559   ?? Smart Ruler ?? cm/inch measuring for homework!                TOOLS   \n",
            "7751                                 ???????? Conquerors               FAMILY   \n",
            "7818                                 ?im Training for CS                 GAME   \n",
            "9117                                   ???? ???? ???? DZ               FAMILY   \n",
            "9200                                           ?????flix               FAMILY   \n",
            "9222                                  ???? EC Dictionary               FAMILY   \n",
            "9308             ????? ?????? | ??? ???? ?? ????? ??????   NEWS_AND_MAGAZINES   \n",
            "9466                     ????????????EJ STYLE???????????             SHOPPING   \n",
            "10109                                            ?????EY        COMMUNICATION   \n",
            "\n",
            "         Rating    Reviews    Installs  Type   Price Content Rating  \\\n",
            "313    4.100000    12088.0   1000000.0  Free    0.00     Mature 17+   \n",
            "321    4.189551     1330.0     50000.0  Free    0.00       Everyone   \n",
            "882    4.700000    11661.0   1000000.0  Free    0.00       Everyone   \n",
            "1081   4.500000   381788.0  10000000.0  Free    0.00       Everyone   \n",
            "1488   3.700000     2248.0    100000.0  Free    0.00       Everyone   \n",
            "1592   4.700000     2225.0    100000.0  Free    0.00       Everyone   \n",
            "2575   4.600000    22098.0   1000000.0  Free    0.00       Everyone   \n",
            "3750   4.500000    44274.0   1000000.0  Free    0.00       Everyone   \n",
            "3824   4.400000    50459.0   5000000.0  Free    0.00       Everyone   \n",
            "3960   4.300000  1305050.0  50000000.0  Free    0.00   Everyone 10+   \n",
            "4193   4.400000       13.0      1000.0  Free    0.00       Everyone   \n",
            "4362   3.800000      718.0     10000.0  Paid  399.99       Everyone   \n",
            "5513   4.189551       21.0      5000.0  Free    0.00       Everyone   \n",
            "5569   4.400000    36268.0   1000000.0  Free    0.00           Teen   \n",
            "5698   4.100000      215.0     10000.0  Free    0.00           Teen   \n",
            "6006   4.300000      193.0     10000.0  Free    0.00       Everyone   \n",
            "6334   4.189551      414.0    100000.0  Free    0.00     Mature 17+   \n",
            "6418   4.700000     6073.0    100000.0  Free    0.00     Mature 17+   \n",
            "6420   4.400000      190.0     10000.0  Free    0.00       Everyone   \n",
            "7183   4.189551       21.0       100.0  Paid    1.49       Everyone   \n",
            "7187   3.200000       27.0      5000.0  Free    0.00       Everyone   \n",
            "7559   4.000000       19.0     10000.0  Free    0.00       Everyone   \n",
            "7751   4.500000   108130.0   5000000.0  Free    0.00           Teen   \n",
            "7818   3.600000     2328.0    100000.0  Free    0.00       Everyone   \n",
            "9117   4.200000      238.0     10000.0  Free    0.00       Everyone   \n",
            "9200   4.200000     1111.0    100000.0  Free    0.00       Everyone   \n",
            "9222   4.300000    55408.0   1000000.0  Free    0.00       Everyone   \n",
            "9308   4.800000      311.0      5000.0  Free    0.00   Everyone 10+   \n",
            "9466   4.189551        1.0       100.0  Free    0.00       Everyone   \n",
            "10109  4.189551      239.0     10000.0  Free    0.00       Everyone   \n",
            "\n",
            "                        Genres  \n",
            "313                     Comics  \n",
            "321                     Comics  \n",
            "882              Entertainment  \n",
            "1081                   Finance  \n",
            "1488              House & Home  \n",
            "1592                 Lifestyle  \n",
            "2575                    Social  \n",
            "3750          News & Magazines  \n",
            "3824         Maps & Navigation  \n",
            "3960                 Adventure  \n",
            "4193              Art & Design  \n",
            "4362                 Lifestyle  \n",
            "5513                 Education  \n",
            "5569             Entertainment  \n",
            "5698         Books & Reference  \n",
            "6006             Entertainment  \n",
            "6334   Video Players & Editors  \n",
            "6418                Simulation  \n",
            "6420                    Comics  \n",
            "7183           Auto & Vehicles  \n",
            "7187                     Tools  \n",
            "7559                     Tools  \n",
            "7751                  Strategy  \n",
            "7818                    Action  \n",
            "9117                 Education  \n",
            "9200             Entertainment  \n",
            "9222                 Education  \n",
            "9308          News & Magazines  \n",
            "9466                  Shopping  \n",
            "10109            Communication  \u001b[0m\u001b[32;1m\u001b[1;3m I need to use the .drop function to drop the selected rows from the dataframe\n",
            "Action: python_repl_ast\n",
            "Action Input: df.drop(df.loc[df['App'].str.startswith('?')].index, inplace=True)\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m I need to check if the rows were successfully dropped\n",
            "Action: python_repl_ast\n",
            "Action Input: print(df.head())\u001b[0m\u001b[36;1m\u001b[1;3m                                                 App        Category  Rating  \\\n",
            "0     Photo Editor & Candy Camera & Grid & ScrapBook  ART_AND_DESIGN     4.1   \n",
            "1                                Coloring book moana  ART_AND_DESIGN     3.9   \n",
            "2  U Launcher Lite – FREE Live Cool Themes, Hide ...  ART_AND_DESIGN     4.7   \n",
            "3                              Sketch - Draw & Paint  ART_AND_DESIGN     4.5   \n",
            "4              Pixel Draw - Number Art Coloring Book  ART_AND_DESIGN     4.3   \n",
            "\n",
            "    Reviews    Installs  Type  Price Content Rating                     Genres  \n",
            "0     159.0     10000.0  Free    0.0       Everyone               Art & Design  \n",
            "1     967.0    500000.0  Free    0.0       Everyone  Art & Design;Pretend Play  \n",
            "2   87510.0   5000000.0  Free    0.0       Everyone               Art & Design  \n",
            "3  215644.0  50000000.0  Free    0.0           Teen               Art & Design  \n",
            "4     967.0    100000.0  Free    0.0       Everyone    Art & Design;Creativity  \n",
            "\u001b[0m\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The updated dataframe with the rows starting with '?' dropped.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"\\nPlease write code to do the following process to update the df\\n- find rows where App column starts with '?'. And drop those rows in the dataframe.\\n\\nand update the orginal df\",\n",
              " 'output': \"The updated dataframe with the rows starting with '?' dropped.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# write your prompt using the agent\n",
        "agent(\"\"\"\n",
        "Please write code to do the following process to update the df\n",
        "- find rows where App column starts with '?'. And drop those rows in the dataframe.\n",
        "\n",
        "and update the orginal df\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# export the cleaned dataframe 'df' with the name 'cleaned_apps_db.csv' using the parameter index=True."
      ],
      "metadata": {
        "id": "K3E53juJStxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nm4JSFeoYeXO",
        "outputId": "4a226b20-3d17-4dac-e7be-ff7af278728e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10325, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "HEhuBs0xFOEZ",
        "run_control": {
          "frozen": true
        }
      },
      "source": [
        "### Task 12: Display Top 5 Records for playstore_reviews.\n",
        "\n",
        "Great! Initializing our another agent(OpenAI) is our next step. Once that's done, we'll create a prompt to display the first 5 records from our playstore_reviews table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "57sg-9KSMMCZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6882d63-3e5f-499a-da26-02be1ea998cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to use the head() function to display the top 5 records\n",
            "Action: python_repl_ast\n",
            "Action Input: print(df.head())\u001b[0m\u001b[36;1m\u001b[1;3m                     App                                  Translated_Review  \\\n",
            "0  10 Best Foods for You  I like eat delicious food. That's I'm cooking ...   \n",
            "1  10 Best Foods for You    This help eating healthy exercise regular basis   \n",
            "2  10 Best Foods for You                                                NaN   \n",
            "3  10 Best Foods for You         Works great especially going grocery store   \n",
            "4  10 Best Foods for You                                       Best idea us   \n",
            "\n",
            "  Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \n",
            "0  Positive                1.00                0.533333  \n",
            "1  Positive                0.25                0.288462  \n",
            "2       NaN                 NaN                     NaN  \n",
            "3  Positive                0.40                0.875000  \n",
            "4  Positive                1.00                0.300000  \n",
            "\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: The top 5 records from df1 are displayed using the head() function.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'display top 5 records from df1',\n",
              " 'output': 'The top 5 records from df1 are displayed using the head() function.'}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "#Load the dataset (playstore_reviews.csv) and assign it to a variable 'df1'.\n",
        "\n",
        "# write your prompt using the agent1\n",
        "df1 = pd.read_csv('playstore_reviews.csv')\n",
        "# Initializing the agent1.\n",
        "agent1 = create_pandas_dataframe_agent(OpenAI(temperature=0),\n",
        "              df1, verbose=True)\n",
        "\n",
        "agent1('display top 5 records from df1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "AnwaMWStGQ4U",
        "run_control": {
          "frozen": true
        }
      },
      "source": [
        "### Task 13: Determine the Shape(Count Rows and Columns) of the Dataset.\n",
        "Great! For our next step, let's create a prompt to gather information about the shape of our playstore_reviews dataset. This will help us understand how many rows and columns it contains."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "I2UPdWJSGRBD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03f2d24b-e730-449b-8566-0fce22b56c50"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64295, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "# write your prompt using the agent1\n",
        "df1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 14: Finding the Missing data.\n",
        "Wow! We've successfully found out the shape of the dataset. Now, let's create a prompt to ask our agent to help us find details about any missing information in the playstore_reviews table."
      ],
      "metadata": {
        "id": "uFwwdQvdRvVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your prompt using the agent1\n",
        "agent1('how many missing values are there in each column')"
      ],
      "metadata": {
        "id": "0YvztIr1Rv3O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "617c5a49-4f6a-41f9-c298-63abb643f979"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to count the number of missing values in each column\n",
            "Action: python_repl_ast\n",
            "Action Input: df.isnull().sum()\u001b[0m\u001b[36;1m\u001b[1;3mApp                           0\n",
            "Translated_Review         26868\n",
            "Sentiment                 26863\n",
            "Sentiment_Polarity        26863\n",
            "Sentiment_Subjectivity    26863\n",
            "dtype: int64\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: There are 26868 missing values in the Translated_Review column, and 26863 missing values in the Sentiment, Sentiment_Polarity, and Sentiment_Subjectivity columns. The App column has no missing values.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'how many missing values are there in each column',\n",
              " 'output': 'There are 26868 missing values in the Translated_Review column, and 26863 missing values in the Sentiment, Sentiment_Polarity, and Sentiment_Subjectivity columns. The App column has no missing values.'}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 15: Identifying Duplicate Rows.\n",
        "Fantastic! We've successfully found the missing values. Now, let's create a prompt to ask our agent to count the number of duplicate rows in the playstore_reviews dataset."
      ],
      "metadata": {
        "id": "zEWdvCUZRwAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your prompt using the agent1\n",
        "agent1(\"\"\"how many duplicate rows are there in dataset 'df1' \"\"\")"
      ],
      "metadata": {
        "id": "zQL0lFiHRwFo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66f7795d-a272-4449-93d5-d48ffe70b5f6"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to use the pandas function 'duplicated' to find duplicate rows\n",
            "Action: python_repl_ast\n",
            "Action Input: df.duplicated()\u001b[0m\u001b[36;1m\u001b[1;3m0        False\n",
            "1        False\n",
            "2        False\n",
            "3        False\n",
            "4        False\n",
            "         ...  \n",
            "64290     True\n",
            "64291     True\n",
            "64292     True\n",
            "64293     True\n",
            "64294     True\n",
            "Length: 64295, dtype: bool\u001b[0m\u001b[32;1m\u001b[1;3mI need to use the pandas function 'sum' to count the number of True values\n",
            "Action: python_repl_ast\n",
            "Action Input: df.duplicated().sum()\u001b[0m\u001b[36;1m\u001b[1;3m33616\u001b[0m\u001b[32;1m\u001b[1;3m33616 duplicate rows were found\n",
            "Final Answer: There are 33616 duplicate rows in dataset 'df1'.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"how many duplicate rows are there in dataset 'df1' \",\n",
              " 'output': \"There are 33616 duplicate rows in dataset 'df1'.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 16: Removing Missing values.\n",
        "Incredible! We were successful in identify the duplicates. Now, let's create a prompt to ask our agent to drop rows with missing values from the playstore_reviews dataset."
      ],
      "metadata": {
        "id": "PamrDKNVSFYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your prompt using the agent1\n",
        "agent1(\"\"\"\n",
        "Please write code to update the dataframe 'df1' by dropping rows with missing values from the dataset 'df1',\n",
        "and update the results to the original dataframe 'df1', Ensure changes are made to the dataframe using appropriate commands\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "Tmm97GImSFdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6342041-60aa-4db8-edf5-73e2f93d3c42"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to use the dropna() function to drop rows with missing values from the dataframe.\n",
            "Action: python_repl_ast\n",
            "Action Input: df1.dropna(inplace=True)\u001b[0m\u001b[36;1m\u001b[1;3mNameError: name 'df1' is not defined\u001b[0m\u001b[32;1m\u001b[1;3mI need to define the dataframe 'df1' before I can use it.\n",
            "Action: python_repl_ast\n",
            "Action Input: df1 = df\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m Now I can use the dropna() function on the dataframe 'df1'.\n",
            "Action: python_repl_ast\n",
            "Action Input: df1.dropna(inplace=True)\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m The missing values have been dropped from the dataframe 'df1'.\n",
            "Final Answer: df1.dropna(inplace=True)\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"\\nPlease write code to update the dataframe 'df1' by dropping rows with missing values from the dataset 'df1', \\nand update the results to the original dataframe 'df1', Ensure changes are made to the dataframe using appropriate commands\\n\",\n",
              " 'output': 'df1.dropna(inplace=True)'}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 17: Removing Duplicate Rows.\n",
        "Great progress! We were successful in dropped the missing values. Now, let's create a prompt to ask our agent to remove duplicate rows from the playstore_reviews dataset."
      ],
      "metadata": {
        "id": "V04WjL8VSFjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XqviB_xZsu3",
        "outputId": "6293c6bb-e099-464b-a0ce-83e29b6e598c"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37427, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# write your prompt using the agent1\n",
        "# write your prompt using the agent1\n",
        "agent1(\"\"\"\n",
        "Please write code to drop duplicate rows from dataframe 'df1' while keeping the first occurrence of each duplicated row, and update the results to the original dataframe 'df1', Ensure changes are made to the dataframe using appropriate commands\"\"\")\n"
      ],
      "metadata": {
        "id": "8VCvHFXmSFoY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5370877-bf8a-4dca-f1a7-072ee81dc169"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to use the drop_duplicates() function to remove duplicate rows from the dataframe.\n",
            "Action: python_repl_ast\n",
            "Action Input: df.drop_duplicates(keep='first', inplace=True)\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mI need to specify the 'keep' parameter as 'first' to keep the first occurrence of each duplicated row.\n",
            "Action: python_repl_ast\n",
            "Action Input: df.drop_duplicates(keep='first', inplace=True)\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m I also need to specify the 'inplace' parameter as 'True' to update the changes to the original dataframe.\n",
            "Action: python_repl_ast\n",
            "Action Input: df.drop_duplicates(keep='first', inplace=True)\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: df.drop_duplicates(keep='first', inplace=True)\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"\\nPlease write code to drop duplicate rows from dataframe 'df1' while keeping the first occurrence of each duplicated row, and update the results to the original dataframe 'df1', Ensure changes are made to the dataframe using appropriate commands\",\n",
              " 'output': \"df.drop_duplicates(keep='first', inplace=True)\"}"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUVO-S36bH8v",
        "outputId": "4686364b-a44e-41c8-8d47-79048f63b1e7"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29692, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "RW-lnKgxFoR2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8280c8d9-51b1-4ac3-acfb-8b47558d0e65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to use the pandas to_csv function to export the dataframe to a csv file.\n",
            "Action: python_repl_ast\n",
            "Action Input: df.to_csv('cleaned_reviews_db.csv', index=True)\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: df.to_csv('cleaned_reviews_db.csv', index=True)\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"\\nexport the cleaned dataframe 'df1' with the name 'cleaned_reviews_db.csv' using the parameter index=True.\\n\",\n",
              " 'output': \"df.to_csv('cleaned_reviews_db.csv', index=True)\"}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "# export the cleaned dataframe 'df1' with the name 'cleaned_reviews_db.csv' using the parameter index=True.\n",
        "\n",
        "agent1(\"\"\"\n",
        "export the cleaned dataframe 'df1' with the name 'cleaned_reviews_db.csv' using the parameter index=True.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n1Q0XAw9b0zr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}